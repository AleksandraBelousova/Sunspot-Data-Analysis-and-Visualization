def extract(file_path):
    try:
        df = pd.read_csv(file_path)
        print(f"Extracted data:\n{df.head()}")
        print(f"Columns in the data: {df.columns.tolist()}")
        return df.replace(-1, np.nan)
    except FileNotFoundError as e:
        print(f"Error: {e}")
        return None

def transform(df):
    if df is None:
        raise ValueError("DataFrame is None, cannot transform.")
    if 'Number of Sunspots' not in df.columns:
        print("Available columns in the DataFrame:", df.columns)
        raise KeyError("Column 'Number of Sunspots' does not exist in the DataFrame.")
    df = df.dropna(subset=['Number of Sunspots']).copy()
    df['log_sunspots'] = np.log1p(df['Number of Sunspots'])
    print(f"Transformed data:\n{df.head()}")
    return df

    df = df.dropna(subset=['Number of Sunspots'])
    df['log_sunspots'] = np.log1p(df['Number of Sunspots'])
    print(f"Transformed data:\n{df.head()}")
    return df

def load(df, db_path='sqlite:///sun_spot.db'):
    if df is None:
        print("No data to load.")
        return
    engine = create_engine(db_path)
    df.to_sql('sunspot_data', con=engine, if_exists='replace', index=False)
    print("Data loaded into database.")

def run_etl(file_path):
    data = extract(file_path)
    transformed_data = transform(data)
    load(transformed_data)

run_etl('/content/data/sunspot_data.csv')
